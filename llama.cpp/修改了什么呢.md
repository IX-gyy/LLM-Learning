# 看看修改了什么
总体上看是想要加入一个叫做`Sparkinfer`的东西，它是一个基于`llama.cpp`的推理优化框架  

## common/arg.cpp
arg.cpp 负责处理`llama.cpp`所有工具（如`llama-cli`、`llama-server`等）的命令行参数解析和配置管理  
添加了3个新命令参数，用于支持`Sparkinfer`的特定功能  
### 1 --sparkinfer-model-split / -spif-ms
指定`Sparkinfer`的模型切分配置文件路径  
其中的字符串执行定义切分方案的配置文件  

### 2 --vram-budget / -vb
设置GPU显存预算上限  
其中的正整数即限制GPU张量占用的最大显存  

### 3 --cpu-ffn / -cffn
强制将所有前馈网络（FFN）权重保存在CPU中  
FFN通常占用模型大部分参数，保存在CPU中可以减少GPU占用  
参数为一个bool值  

## common/common.h
首先将`warmup`改为了`false`  
warmup即**预热**，在正式推理前，先进行1次前向传播，确保所有张量都被实际分配，避免首次推理时的延迟尖峰  
可能后续有自己的内存管理方法？？？  

然后加了2个对应的参数
```cpp
// sparkinfer specific options
std::string spif_ms_path; // 模型切分配置文件路径
int64_t     vram_budget = 0; // GPU显存预算
```

### FFN层匹配的正则表达式系统
精确匹配 FFN 权重，排除偏置项（bias）  
匹配模式：`\.ffn_(up|gate|down)\.weight`  
- ffn_up：FFN 上行投影（如 4096→11008）  
- ffn_gate：门控投影（GLU 变体）  
- ffn_down：FFN 下行投影（如 11008→4096）

排除 bias：正则中明确只匹配 .weight，不匹配 .bias  
目的：偏置项参数量极小，保留在 GPU 上几乎无内存压力，但可减少 CPU/GPU 数据传输开销

### 按层生成FFN正则的辅助函数
生成特定层的 FFN 权重匹配模式  
例如`idx=5`时返回：`blk\.5\.ffn_(up|gate|down)\.weight`  
可能想精准控制某些层留在GPU，另一些放到CPU  

### CPU卸载覆盖配置生成器
核心功能：创建 FFN 层的**CPU缓冲区覆盖配置**  
返回结构体包含：  
- pattern：LLM_FFN_REGEX（匹配所有 FFN 权重）  
- buft：ggml_backend_cpu_buffer_type()（强制使用 CPU 内存）

被`arg.cpp`中的 --cpu-ffn 参数调用，加入 tensor_buft_overrides 列表

## compile_sparkinfer.sh
一个自动化编译脚本，适配Sparkinfer

## convert_hf_to_gguf.py
将模型文件转换为gguf格式（llama.cpp运行模型需要gguf格式）

## ggml/include/ggml-backend.h
ggml的后端部分

### 事件状态
```cpp
enum sparkinfer_event_state { 
    SPIF_EVENT_RECORD = 1,    // 记录事件（标记完成点）
    SPIF_EVENT_WAIT,          // 等待事件（阻塞直到依赖完成）
    SPIF_EVENT_SYNCHRONIZE    // 强制同步（完全等待）
};
```
### 切分标志
```cpp
enum sparkinfer_split_flag { 
    SPIF_SPLIT_MUL_MAT_SPARSE = 1,  // 稀疏矩阵乘法切分
    SPIF_SPLIT_AXPY_SPARSE,         // 稀疏向量运算切分
    SPIF_SPLIT_TAIL,                // 尾部处理（剩余工作）
    SPIF_SPLIT_RELOAD               // 数据重载/刷新
};
```
- 矩阵乘法稀疏切分 → 大矩阵分到多GPU  
- 向量运算稀疏切分  
- 处理剩余部分  
- 显式数据重载  

### 张量扩展结构
```cpp
typedef struct sparkinfer_tensor_extra {
    enum sparkinfer_event_state states[GGML_MAX_SRC];  // 每个输入的状态
    ggml_backend_event_t        events[GGML_MAX_SRC];  // 同步事件对象
    int                         event_count;           // 有效事件数
    enum sparkinfer_split_flag  split_flag;            // 本节点的并行策略
    void *                      spif_executor;         // 执行器句柄（不透明指针）
} sparkinfer_tensor_extra;
```

### 依赖注册函数
```cpp
GGML_API void sparkinfer_register_dependency(
    ggml_backend_sched_t sched,           // 调度器实例
    struct ggml_tensor * src,             // 源节点（生产者）
    struct ggml_tensor * dst,             // 目标节点（消费者）
    ggml_backend_t event_backend,         // 记录事件的后端（如 CUDA）
    enum sparkinfer_event_state src_state, // 源节点动作（通常 RECORD）
    enum sparkinfer_event_state dst_state  // 目标节点动作（通常 WAIT）
);
```
在计算图中显式建立依赖边

### 节点状态设置函数
`GGML_API void sparkinfer_set_node_state`  
由调度器在图优化阶段调用，为每个节点分配合适的并行执行策略  

## ggml/include/ggml-sparkinfer.hpp
包含Sparkinfer的核心机制：*动态神经元缓存*和*异步任务调度*  

### 神经元权重类型和元数据
```cpp
enum sparkinfer_weight_type { SPIF_FFN_UP = 1, SPIF_FFN_GATE, SPIF_FFN_DOWN };

typedef struct {
    int n, m, g;   // n_neuron, n_neuron_cache, n_ffn_group
    int n_g, m_g;  // n_group, n_group_cache
} cache_meta;

typedef struct { int weight_idx, cache_idx; } copy_pair;
```
Sparkinfer实现了FFN的稀疏激活缓存  
FFN包含up、gate、down三个矩阵  
推理时只有部分神经元被激活，所以只加载高频激活的神经元权重到GPU，其他的放在CPU  

### 环境变量控制
| 参数                        | 默认值  | 作用               |
| ------------------------- | ---- | ---------------- |
| `SPIF_DFR_DEBUG`          | 0    | 调试模式开关           |
| `SPIF_INIT_DFR_DECAY`     | 0.67 | 初始衰减系数（冷热权重混合比例） |
| `SPIF_DX_DFR_DECAY`       | 0.05 | 动态调整步长（根据命中率自适应） |
| `SPIF_RELOAD_WINDOW_SIZE` | 4    | 重载历史窗口大小（滑动平均）   |

### 层缓存结构
```cpp
struct sparkinfer_layer_cache {
    // 预测器（学习激活模式）
    ggml_tensor * ffn_pred_up = nullptr;      // 预测哪些 up 神经元会激活
    ggml_tensor * ffn_pred_down = nullptr;    // 预测哪些 down 神经元会激活
    ggml_tensor * ffn_pred_up_b = nullptr;    // 预测器偏置
    ggml_tensor * ffn_pred_down_b = nullptr;

    // 完整权重（CPU 侧存储）
    ggml_tensor * ffn_up, *ffn_gate, *ffn_down;
    ggml_tensor * ffn_up_b, *ffn_gate_b, *ffn_down_b;  // 偏置

    // 热缓存（GPU 侧存储，稀疏子集）
    ggml_tensor * ffn_up_cache, *ffn_gate_cache, *ffn_down_cache;

    // 稀疏索引与重载计划
    ggml_tensor * sparse_idx;     // 哪些神经元索引是稀疏的
    ggml_tensor * reload_up;      // 本次需要重载的 up 索引
    ggml_tensor * reload_gate;    // 本次需要重载的 gate 索引  
    ggml_tensor * reload_down;    // 本次需要重载的 down 索引

    // 神经元分组与掩码（粗粒度管理）
    ggml_tensor * neuron_idx;     // 神经元索引映射
    ggml_tensor * group_maps;     // 分组映射表
    ggml_tensor * neuron_mask;    // 活跃神经元掩码
    ggml_tensor * group_mask;     // 活跃组掩码
    ggml_tensor * dfr_scores;     // 每个神经元的 DFR 分数（优先级）

    cache_meta  layer_cm;         // 缓存元数据（n, m, g 等）
    copy_pair * reload_plan;        // 重载计划（weight_idx → cache_idx）
    bool        gpu_only;           // 是否纯 GPU 模式（无 CPU 回退）

    // 重载统计与自适应
    size_t             reload_count = 0;
    size_t             reload_window_size = k_spif_reload_window_size;
    std::deque<size_t> reload_records;      // 历史重载次数记录
    std::deque<float>  dfr_decay_records;   // 历史衰减系数记录

    // 缓冲区管理
    ggml_tensor * weight_only_buf = nullptr;  // 仅权重缓冲区
    ggml_tensor * cache_only_buf  = nullptr;  // 仅缓存缓冲区
    ggml_tensor * neuron_idx_buf  = nullptr;  // 索引缓冲区
    ggml_tensor * dfr_decay_pack  = nullptr;  // 衰减系数打包

    // 核心方法
    ggml_tensor * build_reload_plan(...);  // 构建重载计划
    ggml_tensor * build_reload_exec(...);  // 执行重载
    void          sparkinfer_reload_plan(); // 触发重载规划
};
```
在**GPU**中（热区），由预测器决定加载哪些神经元  
存放ffn高频激活的up、gate、down投影  
在**CPU**中（冷区）  
存放完整的ffn up、gate、down  
**预测器**：预测哪些神经元会激活  
**索引系统**中，存放`sparse_idx`稀疏索引、`neuron_mask`活跃掩码、`dfr_scores`优先级分数  

### 单线程异步执行器
？？？












