# 看看修改了什么
总体上看是想要加入一个叫做`Sparkinfer`的东西，它是一个基于`llama.cpp`的推理优化框架  

## common/arg.cpp
arg.cpp 负责处理`llama.cpp`所有工具（如`llama-cli`、`llama-server`等）的命令行参数解析和配置管理  
添加了3个新命令参数，用于支持`Sparkinfer`的特定功能  
### 1 --sparkinfer-model-split / -spif-ms
指定`Sparkinfer`的模型切分配置文件路径  
其中的字符串执行定义切分方案的配置文件  

### 2 --vram-budget / -vb
设置GPU显存预算上限  
其中的正整数即限制GPU张量占用的最大显存  

### 3 --cpu-ffn / -cffn
强制将所有前馈网络（FFN）权重保存在CPU中  
FFN通常占用模型大部分参数，保存在CPU中可以减少GPU占用  
参数为一个bool值  

## common/common.h
首先将`warmup`改为了`false`  
warmup即**预热**，在正式推理前，先进行1次前向传播，确保所有张量都被实际分配，避免首次推理时的延迟尖峰  
可能后续有自己的内存管理方法？？？  

然后加了2个对应的参数
```cpp
// sparkinfer specific options
std::string spif_ms_path; // 模型切分配置文件路径
int64_t     vram_budget = 0; // GPU显存预算
```

### FFN层匹配的正则表达式系统
精确匹配 FFN 权重，排除偏置项（bias）  
匹配模式：`\.ffn_(up|gate|down)\.weight`  
- ffn_up：FFN 上行投影（如 4096→11008）  
- ffn_gate：门控投影（GLU 变体）  
- ffn_down：FFN 下行投影（如 11008→4096）

排除 bias：正则中明确只匹配 .weight，不匹配 .bias  
目的：偏置项参数量极小，保留在 GPU 上几乎无内存压力，但可减少 CPU/GPU 数据传输开销

### 按层生成FFN正则的辅助函数
生成特定层的 FFN 权重匹配模式  
例如`idx=5`时返回：`blk\.5\.ffn_(up|gate|down)\.weight`  
可能想精准控制某些层留在GPU，另一些放到CPU  

### CPU卸载覆盖配置生成器
核心功能：创建 FFN 层的**CPU缓冲区覆盖配置**  
返回结构体包含：  
- pattern：LLM_FFN_REGEX（匹配所有 FFN 权重）  
- buft：ggml_backend_cpu_buffer_type()（强制使用 CPU 内存）

被`arg.cpp`中的 --cpu-ffn 参数调用，加入 tensor_buft_overrides 列表

## compile_sparkinfer.sh
一个自动化编译脚本，适配Sparkinfer

## convert_hf_to_gguf.py
将模型文件转换为gguf格式（llama.cpp运行模型需要gguf格式）

## ggml/include/ggml-backend.h
ggml的后端部分

### 事件状态
```cpp
enum sparkinfer_event_state { 
    SPIF_EVENT_RECORD = 1,    // 记录事件（标记完成点）
    SPIF_EVENT_WAIT,          // 等待事件（阻塞直到依赖完成）
    SPIF_EVENT_SYNCHRONIZE    // 强制同步（完全等待）
};
```
### 切分标志
```cpp
enum sparkinfer_split_flag { 
    SPIF_SPLIT_MUL_MAT_SPARSE = 1,  // 稀疏矩阵乘法切分
    SPIF_SPLIT_AXPY_SPARSE,         // 稀疏向量运算切分
    SPIF_SPLIT_TAIL,                // 尾部处理（剩余工作）
    SPIF_SPLIT_RELOAD               // 数据重载/刷新
};
```
- 矩阵乘法稀疏切分 → 大矩阵分到多GPU  
- 向量运算稀疏切分  
- 处理剩余部分  
- 显式数据重载  

### 张量扩展结构
```cpp
typedef struct sparkinfer_tensor_extra {
    enum sparkinfer_event_state states[GGML_MAX_SRC];  // 每个输入的状态
    ggml_backend_event_t        events[GGML_MAX_SRC];  // 同步事件对象
    int                         event_count;           // 有效事件数
    enum sparkinfer_split_flag  split_flag;            // 本节点的并行策略
    void *                      spif_executor;         // 执行器句柄（不透明指针）
} sparkinfer_tensor_extra;
```

### 依赖注册函数
```cpp
GGML_API void sparkinfer_register_dependency(
    ggml_backend_sched_t sched,           // 调度器实例
    struct ggml_tensor * src,             // 源节点（生产者）
    struct ggml_tensor * dst,             // 目标节点（消费者）
    ggml_backend_t event_backend,         // 记录事件的后端（如 CUDA）
    enum sparkinfer_event_state src_state, // 源节点动作（通常 RECORD）
    enum sparkinfer_event_state dst_state  // 目标节点动作（通常 WAIT）
);
```
在计算图中显式建立依赖边

### 节点状态设置函数
`GGML_API void sparkinfer_set_node_state`  
由调度器在图优化阶段调用，为每个节点分配合适的并行执行策略  

## ggml/include/ggml-sparkinfer.hpp
包含Sparkinfer的核心机制：*动态神经元缓存*和*异步任务调度*  

### 神经元权重类型和元数据
```cpp
enum sparkinfer_weight_type { SPIF_FFN_UP = 1, SPIF_FFN_GATE, SPIF_FFN_DOWN };

typedef struct {
    int n, m, g;   // n_neuron, n_neuron_cache, n_ffn_group
    int n_g, m_g;  // n_group, n_group_cache
} cache_meta;

typedef struct { int weight_idx, cache_idx; } copy_pair;
```
Sparkinfer实现了FFN的稀疏激活缓存  
FFN包含up、gate、down三个矩阵  
推理时只有部分神经元被激活，所以只加载高频激活的神经元权重到GPU，其他的放在CPU  

### 环境变量控制
| 参数                        | 默认值  | 作用               |
| ------------------------- | ---- | ---------------- |
| `SPIF_DFR_DEBUG`          | 0    | 调试模式开关           |
| `SPIF_INIT_DFR_DECAY`     | 0.67 | 初始衰减系数（冷热权重混合比例） |
| `SPIF_DX_DFR_DECAY`       | 0.05 | 动态调整步长（根据命中率自适应） |
| `SPIF_RELOAD_WINDOW_SIZE` | 4    | 重载历史窗口大小（滑动平均）   |

### 层缓存结构
```cpp
struct sparkinfer_layer_cache {
    // 预测器（学习激活模式）
    ggml_tensor * ffn_pred_up = nullptr;      // 预测哪些 up 神经元会激活
    ggml_tensor * ffn_pred_down = nullptr;    // 预测哪些 down 神经元会激活
    ggml_tensor * ffn_pred_up_b = nullptr;    // 预测器偏置
    ggml_tensor * ffn_pred_down_b = nullptr;

    // 完整权重（CPU 侧存储）
    ggml_tensor * ffn_up, *ffn_gate, *ffn_down;
    ggml_tensor * ffn_up_b, *ffn_gate_b, *ffn_down_b;  // 偏置

    // 热缓存（GPU 侧存储，稀疏子集）
    ggml_tensor * ffn_up_cache, *ffn_gate_cache, *ffn_down_cache;

    // 稀疏索引与重载计划
    ggml_tensor * sparse_idx;     // 哪些神经元索引是稀疏的
    ggml_tensor * reload_up;      // 本次需要重载的 up 索引
    ggml_tensor * reload_gate;    // 本次需要重载的 gate 索引  
    ggml_tensor * reload_down;    // 本次需要重载的 down 索引

    // 神经元分组与掩码（粗粒度管理）
    ggml_tensor * neuron_idx;     // 神经元索引映射
    ggml_tensor * group_maps;     // 分组映射表
    ggml_tensor * neuron_mask;    // 活跃神经元掩码
    ggml_tensor * group_mask;     // 活跃组掩码
    ggml_tensor * dfr_scores;     // 每个神经元的 DFR 分数（优先级）

    cache_meta  layer_cm;         // 缓存元数据（n, m, g 等）
    copy_pair * reload_plan;        // 重载计划（weight_idx → cache_idx）
    bool        gpu_only;           // 是否纯 GPU 模式（无 CPU 回退）

    // 重载统计与自适应
    size_t             reload_count = 0;
    size_t             reload_window_size = k_spif_reload_window_size;
    std::deque<size_t> reload_records;      // 历史重载次数记录
    std::deque<float>  dfr_decay_records;   // 历史衰减系数记录

    // 缓冲区管理
    ggml_tensor * weight_only_buf = nullptr;  // 仅权重缓冲区
    ggml_tensor * cache_only_buf  = nullptr;  // 仅缓存缓冲区
    ggml_tensor * neuron_idx_buf  = nullptr;  // 索引缓冲区
    ggml_tensor * dfr_decay_pack  = nullptr;  // 衰减系数打包

    // 核心方法
    ggml_tensor * build_reload_plan(...);  // 构建重载计划
    ggml_tensor * build_reload_exec(...);  // 执行重载
    void          sparkinfer_reload_plan(); // 触发重载规划
};
```
在**GPU**中（热区），由预测器决定加载哪些神经元  
存放ffn高频激活的up、gate、down投影  
在**CPU**中（冷区）  
存放完整的ffn up、gate、down  
**预测器**：预测哪些神经元会激活  
**索引系统**中，存放`sparse_idx`稀疏索引、`neuron_mask`活跃掩码、`dfr_scores`优先级分数  

### 单线程异步执行器
~~猜测一下~~：  
传统多线程中，多个线程竞争锁，并且任务分配也需要一定的策略  
而单线程比较简单，不用考虑锁和分配问题  

双队列：`tasks`计算任务队列、`io_tasks`I/O任务队列  
~~再次猜测~~：I/O任务从CPU内存拷贝权重，计算任务在GPU中执行，两者分开可以充分利用GPU算力  

#### Anchor机制
```cpp
struct AnchorState {
    bool has_anchor = false;   // 是否启用锚点
    bool active = false;       // 锚点是否激活（正在等待）
    std::deque<std::function<void()>> pending; // 被锚点拦截的任务
};
// 2种锚类型
AnchorState anchor_mm_sparse_;   // 稀疏矩阵乘法锚点
AnchorState anchor_axpy_sparse_;   // 稀疏向量运算锚点
```
假设没有**锚**机制：现在有ABCD 4个任务，第1轮先输入ABC到GPU中，D任务依赖于A任务的结果  
当A任务完成时现在想要先完成D任务，但是前面还有BC，无法在处理完A后立即处理相关的D  

假设设置了**锚**：依然是刚才那种情况，当A插入时我们启动锚，插入BC时发现锚已经启动，插入到`pending`队列中  
A执行完毕后就能执行D，如果D没有后续任务就可以将`active=true`，`pending`中的任务也重回任务列表`tasks`  
其中`submit`和`make_anchor`方法是实现锚的关键函数  

#### 可能的完整执行流程
FFN层推理  
1. 预测阶段：在GPU中，调用`submit`函数将任务入队`tasks`
2. 预测完成后，设置锚点：后续任务被拦截
3. 在CPU中，`submit`任务被锚拦截，加入`pending`队列中
4. 在刚才这个过程中，`post`函数将任务加入I/O队列中，可以直接执行（无论有没有锚）
5. 锚关闭：将`pending`中的任务放回队列中
6. 循环

其中`submit`函数用于提交矩阵乘法、激活函数等计算任务；`post`则提交权重载入、数据拷贝、日志等任务  

## ggml/src/ggml-cpu/ops.cpp
`ggml/src/ggml-cpu/ops.cpp`是CPU实现的一部分，*可能*和CUDA版本对应（因为有一个`ggml-cuda/ops.cpp`），*在GPU不足时可以调用*  
添加了`ggml_compute_forward_fatrelu`，实现了`FATReLU`激活函数，是`Sparkinfer`针对稀疏激活预测设计的算子

### 什么是FATReLU?
标准的ReLU：`f(x)=max(0,x)`  
FATReLU：`f(x)=max(threshold,x)`，其中`threshold`为阈值，可以调节来控制稀疏度  
也就是说这个函数可以和预测器相互配合，通过调节参数，明确杀死部分神经元，实现了显式控制神经元的功能  

## ggml/src/ggml-cuda/axpy-sparse.cu
一个用于**稀疏矩阵-向量乘法**的CUDA实现  
文件实现了`ggml_cuda_op_axpy_sparse`函数，执行的是带稀疏掩码的AXPY操作（`y ← αx+y`）  
其中：
```cpp
if (sparse_tok[neu] < threshold || alpha_fp32 == 0.0f) {
    return;  // 跳过稀疏或零激活的神经元
}
```

## ggml/src/ggml-cuda/axpyq-sparse.cu
和刚才那个文件差不多，但是这个是针对`Q8_0`量化格式（8比特量化，块大小32）的，和刚才针对FP稠密版本形成互补  
每个量化块34字节，用2个字节存放块缩放因子`d`，32字节存放32个int8量化值`qs`  
随后得到反量化后的原始值`w=d×qs[i]`

## ggml/src/ggml-cuda/binbcast.cu
为llama.cpp添加了3种二元广播操作：`Scale-Add EMA`、`XOR`、`AND`  

### 常量内存dfr_decay_pack
通过CUDA常量内存实现快速访问，避免重复读取  
[0]：存放缩放因子scale  
[1]：存放EMA系数  
[2]：除数div  

### 二元操作
```cpp
// 基础版本：dst = scale * src0 + (src1 / div)
op_scale_add(a, b)   = dfr_decay_pack[0] * a + (b / dfr_decay_pack[2])

// EMA 版本：dst = scale * src0 + ema * (src1 / div)  
op_scale_add_ema(a, b) = dfr_decay_pack[0] * a + dfr_decay_pack[1] * (b / dfr_decay_pack[2])
```
DFR核心操作，其中`src0`是历史累积特征，`src1`是当前新特征

```cpp
op_xor(a, b) = float(int(a) ^ int(b))
```
异或

```cpp
op_and(a, b) = float(int(a) & int(b))
```
与

## ggml/src/ggml-cuda/mm-sparse.cu
???

## 
















