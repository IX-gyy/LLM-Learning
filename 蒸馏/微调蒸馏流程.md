# 1、准备阶段
## 创建虚拟环境
1. 使用下面的语句在当前文件夹创建虚拟环境文件夹`myenv`
```bash
conda create -p ./myenv python=3.10.0 -y
```
2. 激活bash，虽然已经创建了虚拟环境，但是shell还没有识别
```bash
conda init bash
source ~/.bashrc
```
3. 激活虚拟环境
```bash
conda activate ./myenv
```
4. 下载依赖
```bash
conda install pip
pip install vllm
pip install llmcompressor
```

## 解决网络问题
在AutoDL的帮助文档中找到“学术资源加速”  
命令行输入指令：
```
source /etc/network_turbo
```
**如果要用到huggingface的数据集**，还需要：
```
export HF_ENDPOINT=https://hf-mirror.com
```

# 2、模型下载
本次使用Qwen2.5-7B作为教师模型，Qwen2.5-1.5B作为学生模型  
但是因为目标为`数学测评集输入给7B,输入和输出拼接输入给1.5B训练,看是否提升`  
微调的成果可能不好，我们直接使用Qwen2.5-7B-Math作为教师模型（在原模型基础上进行Math数据集微调）  

使用魔搭平台一键下载(https://www.modelscope.cn/)
```bash
modelscope download --model Qwen/Qwen2.5-Math-7B --local_dir ./models/Qwen2.5-Math-7B
modelscope download --model Qwen/Qwen2.5-Math-1.5B --local_dir ./models/Qwen2.5-Math-1.5B
```

# 3、数据集下载
```python
from datasets import load_dataset

# 设置本地缓存路径
custom_cache_dir1 = "./datasets/gsm8k"
ds = load_dataset("openai/gsm8k", "main", cache_dir=custom_cache_dir1)
```

# 4、模型微调
```python

```

# 5、评估
```bash
lm_eval --model vllm \
  --model_args pretrained="./models/Qwen2.5-7B-Math",add_bos_token=true \
  --tasks gsm8k \
  --num_fewshot 5 \
  --limit 250 \
  --batch_size 'auto' \
  --output_path eval_out/Qwen_out
```
