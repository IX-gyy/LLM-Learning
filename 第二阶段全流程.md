# 第二阶段全流程

> - 跑通https://github.com/vllm-project/llm-compressor上的代码
> - 在huggface上自行选择一个模型进行量化
> - 使用https://github.com/EleutherAI/lm-evaluation-harness评估模型
> - 修改代码增加模型量化之后的准确度

## 跑通llm-compressor上的代码
可以在其`example`文件夹中选择具体的量化方法进行实验 (不知道什么原因，它的*QuickStart*代码跑不通)  
**在下载前记得设置镜像，否者下载有可能失败**  
我们先将模型下载到本地(代码见`download.py`)，指定文件夹下的`.safetensors`文件就是模型，可以看一下有多大。  
然后对模型进行量化(代码见`1.py`)，量化完成后也会产生一个输出文件夹，量化后的模型最直观的效果就是大小变小，可以对比一下。  
最后可以对量化前后的模型进行评估(代码见`eval.py`)  

## 选择模型自行量化
在huggface上找到一个模型(可能要根据自己租的机子来选择模型，7B往上的一般装不下)  
仿照上面的流程进行下载、量化、评估  

## 修改代码增加准确度
打开https://github.com/vllm-project/llm-compressor上的example文件夹，可以看见有很多量化方法  
